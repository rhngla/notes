
---
title: "Variational Autoencoders"
author: "Rohan Gala"
date: "2023-06-20"
date-modified: last-modified
categories: ["math"]
toc: true
number-sections: true
number-depth: 2
highlight-style: pygments
html-math-method: katex
bibliography: "../refs.bib"
code-fold: true
---

<!-- ---
title: "Variational Autoencoders"
author: Rohan Gala
toc: true
number-sections: true
number-depth: 2
highlight-style: pygments
bibliography: ../refs.bib

format:
  html:
    theme: journal
    code-fold: true
    html-math-method: katex

editor:
    render-on-save: true
--- -->

There is a class of inference problems for which we use approximate methods. Approximate methods are grouped into 

1. Deterministic approximations
    - Maximum likelihood estimation 
    - Variational inference
2. Monte Carlo methods

Some resources I used to compile this post:

 - [Jaan Altosaar's blog](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/)
 - [Yuge Shi's blog](https://yugeten.github.io/posts/2020/06/elbo/)
 - [Adam Kosiorek's blog](http://akosiorek.github.io/what_is_wrong_with_vaes/)
 - [Matthew Bernstein's blog](https://mbernste.github.io/posts/vae/)
 - @hoffman2016elbo

I'll use the following notational convention: 

 | Notation |       What we mean |
 |:--------:|:------------------:|
 | $p(x)$   | $p_{X}(X=x)$       |
 | $q(x)$   | $q_{X}(X=x)$       |
 | $p(x|z)$ | $p_{X|Z}(X=x|Z=z)$ |
 | $p(x,z)$ | $p_{X,Z}(X=x,Z=z)$ |


::: {.callout-note}
According notation indicated in the table, for a continuous random variable $X$, $p(x)$ is a probability density evaluated at the point $X=x$ based on the distribution $p_X$.

In blog posts, research papers and even textbooks, $p(x)$ is used to refer to either the probability density $p_X(X=x)$, or the distribution itself $p_X$ depending on context.

This eventually becomes easier to parse from context, but was a source of confusion for me. Such [_abuse of notation_](https://statmodeling.stat.columbia.edu/2020/02/05/abuse-of-expectation-notation/) is unfortunately common in literature.
:::

We view individual data points as particular values $x$ of random variable $X$ drawn from it's distribution $p_X$, indicated as $x \sim p_X$. 

When $p_X$ is being modeled by some distribution with parameters $\theta$, we'll write $p_{X|\theta}$. Here we'll refer to parameter as objects whose values are we want to determine, e.g. through an optimization procedure.

When we are trying to estimate the distribution, but only have access to a bunch of samples, it makes sense to think of the $p(X=x| \theta)$ as _evidence_. 


In such a scenario, it makes sense to refer to the likelihood of observing _Evidence_ refers to probability of the data under the model, $p_X(x)$. Using the law of total probability:

$$p_X(x) = \int p_{X,Z}(x, z) dz = \int p_{X|Z}(x|z) p_Z(z) dz$${#eq-total-prob}

We do not know $p_Z$ or $p_{X|Z}$. Integrating over $z$ is intractable for many problems. 

We introduce a known distribution $q(z)$, which will be our best guess of the true distribution $p(z)$. 

Then we introduce parameters $\theta$ to specify the dependence of $X$ on $Z$, i.e. $p_X|Z$ in a flexible manner $p_{X|Z;\theta}(x|z;\theta)$ (equivalently written as $p_{\theta}(x|z)$). 

Then:

$$
\begin{aligned}
p(x) &= \int p_{\theta}(x|z) p(z) \frac{q(z)}{q(z)} dz \\
\log p(x) &= \log \int p_{\theta}(x|z) p(z) \frac{q(z)}{q(z)} dz \\
&=  \log \mathbf{E}_{z \sim q} \bigg[ \frac{p_{\theta}(x|z) p(z)}{q(z)} \bigg] \\
&\geq \mathbf{E}_{z \sim q} \log  \bigg[ \frac{p_{\theta}(x|z) p(z)}{q(z)} \bigg] \\
&\geq \mathbf{E}_{z \sim q} [ \log  p_{\theta}(x|z)] - D_{KL}(q(z)\|p(z)) 
\end{aligned}
$$

### References

::: {#refs}
:::